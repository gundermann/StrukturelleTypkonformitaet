\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{float}
\usepackage{listings}
\usepackage{color}
\usepackage{graphicx}
\graphicspath{ {./pics/} }

\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}

\lstdefinestyle{dsl}{
	 morekeywords={with, proxy, structproxy, for, simpleproxy, contentproxy, containerproxy, nominalproxy, provided, required, interface, extends, inject, in, posModi},
  showspaces=false,
  showtabs=false,
  breaklines=true,
   literate=
               {-->}{$\rightarrow{}$}{1}
               ,
  showstringspaces=false,
  breakatwhitespace=true,
  commentstyle=\color{pgreen},
  keywordstyle=\color{pblue},
  stringstyle=\color{pred},
  basicstyle=\fontsize{9}{10}\selectfont\ttfamily,
  moredelim=[il][\textcolor{pgrey}]{$ $},
  moredelim=[is][\textcolor{pgrey}]{\%\%}{\%\%}
}


\lstdefinestyle{dsl}{
mathescape,  
	 morekeywords={function, for, if, return },
  showspaces=false,
  showtabs=false,
  breaklines=true,
  showstringspaces=false,
  breakatwhitespace=true,
  commentstyle=\color{pgreen},
  keywordstyle=\color{pblue},
  stringstyle=\color{pred},
  basicstyle=\fontsize{9}{10}\selectfont\ttfamily,
  moredelim=[il][\textcolor{pgrey}]{$ $},
  moredelim=[is][\textcolor{pgrey}]{\%\%}{\%\%}
}




\newcommand{\matchTyp}[3]
{
#1  
\Rightarrow_{#2}
 #3
}

\begin{document}


\section{Semantische Evaluation}
Das Ziel der semantischen Evaluation ist es, einen der Proxies, die im Rahmen der 1. Stufe der Exploration erzeugt wurden, hinsichtlich der vordefinierten Testfälle zu evaluieren. Da die gesamte Exploration zur Laufzeit des Programms durchgeführt wird, stellt sie hinsichtlich der nicht-funktionalen Anforderungen eine zeitkritische Komponente dar.\\\\
Da die Anforderungen an die gesuchte Komponente mit bedacht spezifiziert werden müssen, ist es irrelevant, ob es mehrere Proxies gibt, die den vordefinierten Testfällen standhalten. Vielmehr soll bei der semantischen Evaluation lediglich ein Proxy gefunden werden, dessen Semantik zu positiven Ergebnissen hinsichtlich aller vordefinierten Testfälle führt. Somit wird die semantische Evaluation beendet, sobald ein solcher Proxy gefunden ist.\\\\
Bei der Exploration soll letztendlich in einer Bibliothek $L$ zu einem vorgegebenen required Type $R$ ein Proxy gefunden werden. Die Menge dieser Proxies wurde im vorherigen über $\mathit{cover(R,L)}$ beschrieben. Die in dieser Menge befindlichen Proxies können eine unterschiedliche Anzahl von Target-Typen enthalten.\\\\
Das in dieser Arbeit beschriebene Konzept basiert auf der Annahme, dass bei der Entwicklung davon ausgegangen wird, dass der gesamte Anwendungsfall - oder Teile davon - , der mit der vordefinierten Struktur und den vordefinierten Tests abgebildet werden soll, schon einmal genauso oder so ähnlich in dem gesamten System implementiert wurde. Aus diesem Grund kann für die semantische Evaluation grundsätzlich davon ausgegangen werden, dass die erfolgreiche Durchführung aller relevanten Tests umso wahrscheinlicher ist je weniger Target-Typen im Proxy verwendet werden.\\\\
Somit werden zuerst die Proxies auf ihr semantisches Matching überprüft, in denen lediglich ein Target-Typ verwendet wird. Die Menge der Proxies aus einer Menge von Proxies $P$ mit einer Anzahl $A$ von Target-Typen wird durch folgende Funktion beschrieben:
\begin{gather*}
proxiesMitTargets(P,A) := \{P | P.targetCount = A\}
\end{gather*}
Die maximale Anzahl der Target-Typen in einerm Proxy zu einem required Typ $R$ ist gleich der Anzahl der Methoden in P.
\begin{gather*}
maxTargets(R) := |\mathit{methoden(R)}|
\end{gather*}
So kann der Algorithmus für die semantische Evaluation der Menge $P$ von Proxies, die für einen required Typ $R$ erzeugt wurden, mit der Menge von Testfällen $T$ wie folgt im Pseudo-Code beschrieben werden. Dabei sei davon auszugehen, dass ein Test aus $T$ mit einem Proxy $p$ über eine Methode $\texttt{eval(p)}$ ausgewertet werden kann. Diese Methode gibt bei erfolgreicher Durchführung den Rückgabewert $\texttt{true}$ und anderenfalls $\texttt{false}$ zurück.
\begin{lstlisting}[style = dsl]
function semanticEval(R, P, T){
	for( i = 1; i <= maxTargets(R); i++ ){
		proxy = evalProxiesMitTarget(P,i,T)	
		if( proxy != null ){
			// passenden Proxy gefunden
			return proxy
		}
	}
	// kein passenden Proxy gefunden
	return null;
}

function evalProxiesMitTarget(P,anzahl,T){
	for( proxy : relevantProxies(P,anzahl) ){
		if( evalProxy(proxy, T) ){
			// passenden Proxy gefunden
			return proxy
		}
	}
	// kein passenden Proxy gefunden
	return null
}

function relevantProxies(P,anzahl){
	return proxiesMitTargets(P,anzahl);
}

function evalProxy(proxy, T){
	for( test : T ){
		if( !test.eval(proxy) ){
			\\ wenn ein Test fehlschlaegt, dann entspricht der 
			\\ Proxy nicht den semantischen Anforderungen
			return false
		}
	}
	return true
}
\end{lstlisting}
Die Dauer der Laufzeit der oben genannten Funktionen hängt maßgeblich von der Anzahl der Proxies $\mathit{PA}$ ab. Im schlimmsten Fall müssen alle Proxies hinsichtlich der vordefinierten Tests evaluiert werden.\\\\
Die Heuristiken, die in den folgenden Abschnitten vorgestellt werden, sollen im Allgemeinen die Anzahl der zu prüfenden Proxies reduzieren. Sie werden immer innerhalb der Methode $\texttt{relevantProxies}$ angewendet. So kann diese Methode wie in folgendem Listing erweitert werden. Die jeweilige Heuristik wird dann über die Methode $\texttt{applyHeuristic}$ beschrieben.
\begin{lstlisting}[style = dsl]

function relevantProxies(P,anzahl){
	proxies = proxiesMitTargets(P,anzahl)
	optmizedProxies = applyHeuristic(proxies)
	return optmizedProxies
}

\end{lstlisting}

\subsection{Ratingbasierte Heuristiken}
Die folgenden Heuristiken haben zum Ziel, die Reihenfolge, in der die Proxies hinsichtlich der vordefinierten Tests evaluiert werden, so anzupassen, dass ein passender Proxy möglichst früh evaluiert wird. Dabei dient jeweils ein Rating der Proxies als Kriterium für die Festlegung der Reihenfolge.


\subsubsection{Qualitatives Rating}
Bei dem so genannten \emph{qualitative Rating} eines Proxies handelt es sich um einen numerischen Wert. Um diesen Wert zu ermitteln, wird für jeden Matcher ein Basisrating vergeben. Folgende Funktion beschreibt das Basisrating für das Matching zweier Typen $S$ und $T$:
\begin{gather*}
\mathit{base(S,T)} =  \left\{ 
				\begin{array}{l|l}
					S \Rightarrow_{exact}  T  & 100 \\
					S \Rightarrow_{gen}  T  & 200 \\
					S \Rightarrow_{spec}  T  & 200 \\
					S \Rightarrow_{contained}  T  & 300 \\
					S \Rightarrow_{container}  T  & 300 					
				\end{array}
              \right\}
\end{gather*}
\noindent
%, welche in der folgenden Tabelle aufgeführt sind.
%\begin{table}[H]
%\centering
%\begin{tabular}{|p{5cm}|p{3cm}|}
%\hline
%\hline
%\textbf{Matcher} & \textbf{Basisrating} \\
%\hline
%\hline
%\emph{ExactTypeMatcher} & 100\\
%\hline
%\emph{GenTypeMatcher} & 200\\
%\hline
%\emph{SpecTypeMatcher} & 200\\
%\hline
%\emph{ContentTypeMatcher} & 300\\
%\hline
%\emph{ContainerTypeMatcher} & 300\\
%\hline
%\hline
%\end{tabular}
%\caption{Basisrating der Matcher}
% \label{tab:baseRating}
%\end{table}
%\noindent
Dabei ist zu erwähnen, dass einige der o.g. Matcher über dasselbe Basisrating erfügen. Das liegt daran, dass sie technisch jeweils gemeinsam umgesetzt wurden.\footnote{Der \emph{GenTypeMatcher} und der \emph{SpecTypeMatcher} wurden gemeinsam in der Klasse $\texttt{GenSpecTypeMatcher}$ umgesetzt. Der \emph{ContentTypeMatcher} und der \emph{ContainerTypeMatcher} wurden gemeinsam in der Klasse $\texttt{WrappedTypeMatcher}$ umgesetzt. (siehe angehängter Quellcode)}\\\\
Das qualitative Rating eines Proxies $P$ wird über die Funktion $\mathit{qualRating(P)}$ beschrieben. Dieses ist von dem qualitativen Rating der Methoden-Delegation innerhalb des Proxies $P$ abhängig. Das qualitative Rating einer Methoden-Delegation ist von den Basisratings der Matcher abhängig, über die die Parameter- und Rückgabe-Typen der aufgerufenen Methode und der Delegationsmethoden gematcht werden können. Das qualitative Rating einer Methoden-Delegation $\mathit{MD}$ soll über die Funktion $\mathit{mdRating(MD)}$ beschrieben werden.\\\\
Für die Definition der beiden Funktionen $\mathit{qualRating(P)}$ und $\mathit{mdRating(MD)}$ gibt es unterschiedliche Möglichkeiten. In dieser Arbeit werden 4 Varianten als Definitionen vorgeschlagen, die in einem späteren Abschnitt untersucht werden.\\\\
Für die Vorschläge zur Definition von $\mathit{qualRating(P)}$ sei $P$ ein struktureller Proxy mit $n$ Methoden-Delegation.
Darüber hinaus gelten für die Definition von $\mathit{mdRating(MD)}$ für eine Methoden-Delegation $\mathit{MD}$ folgende verkürzte Schreibweisen:
\begin{gather*}
	\mathit{pc} := \mathit{MD.call.paramCount}
	\\
	\mathit{cRT} := \mathit{MD.call.returnType}
	\\
	\mathit{dRT} := \mathit{MD.del.returnType}
	\\
	\mathit{cPT} := \mathit{MD.call.paramTypes}
	\\
	\mathit{dPT} := \mathit{MD.del.paramTypes}
	\\
	\mathit{pos} := \mathit{MD.call.posModi}
\end{gather*}
Weiterhin seien die folgenden Funktionen gegeben:
\begin{gather*}
\mathit{basesMD(MD)} =  
				\begin{array}{l}
					  \mathit{base(dRT, cRT)} \mathit{ }\cup \mathit{base(cPT[0],dPT[pos[0]])} \\
					  \mathit{ }\cup ... \cup \mathit{base(cPT[pc],dPT[pos[pc]])}
				\end{array}    
				\\\\
				\mathit{sum(v_1,...v_n)} = \sum_{i=1}^{n}v_i
\\\\         
\mathit{max(v_1,...,v_n)} = v_{m}| 1 \leq m \leq n  \wedge \forall i \in  \{1,...,n\}: v_i \leq v_{m}
\\\\       
\mathit{min(v_1,...,v_n)} = v_{m}| 1 \leq m \leq n  \wedge \forall i \in  \{1,...,n\}: v_i \geq v_{m}
\\\\    
\end{gather*}



\paragraph{Variante 1: Durchschnitt}

\begin{gather*}
\mathit{mdRating(MD)} = \frac{\mathit{sum(basesMD(MD))}}{\mathit{pc} + 1}
\\\\
\mathit{qualRating(P)} = \frac{ \mathit{sum(mdRating(P.dels[0]),...,mdRating(P.dels[n-1]))}}{n}
\end{gather*}



\paragraph{Variante 2: Maximum}

\begin{gather*}
\mathit{mdRating(MD)} = \mathit{max(basesMD(MD))}
\\\\
\mathit{qualRating(P)} = \frac{\mathit{max(mdRating(P.dels[0]),...,mdRating(P.dels[n-1]))}}{n}
\end{gather*}



\paragraph{Variante 3: Minimum}

\begin{gather*}
\mathit{mdRating(MD)} = \mathit{min(basesMD(MD))}
\\\\
\mathit{qualRating(P)} = \frac{\mathit{min(mdRating(P.dels[0]),...,mdRating(P.dels[n-1]))}}{n}
\end{gather*}

\paragraph{Variante 4: Durchschnitt aus Minimum und Maximum}

\begin{gather*}
\mathit{mdRating(MD)} = \frac{\mathit{max(basesMD(MD))}+\mathit{min(basesMD(MD))}}{2}
\\\\
\mathit{qualRating(P)} = \frac{\splitfrac{ \mathit{max(mdRating(P.dels[0]),...,mdRating(P.dels[n-1]))}}{+\mathit{min(mdRating(P.dels[0]),...,mdRating(P.dels[n-1]))}}}{2}
\end{gather*}
\noindent
Da die Funktion $\mathit{qualRating}$ von $\mathit{mdrating}$ abhängt und für $\mathit{mdrating}$ 4 Variante gegeben sind, ergeben sich für jede gegebene Variante für die Definition von $\mathit{qualRating}$ weitere 4 Varianten. Dadurch sind insgesamt 16 Varianten für die Definition von $\mathit{qualRating}$ gegeben.\\\\
Zur Anwendung der Heuristik muss das qualitative Rating bei der Auswahl der Proxies in der semantischen Evaluation beachtet werden. Die erfolgt innerhalb der Methode $\texttt{applyHeuristic(proxies)}$. Für diese Heuristik sei dazu eine Methode $\texttt{sort(proxies, rateFunc)}$ angenommen, die eine Liste zurückgibt, in der die Elemente in der übergebenen Liste $\texttt{proxies}$ aufsteigend nach den Werten sortiert, die durch die Applikation der übergebenen Funktion $\texttt{rateFunc}$ auf ein einzelnes Element aus der Liste $\texttt{proxies}$ ermittelt werden. Darauf aufbauend wird die Methode $\texttt{applyHeuristic(proxies)}$ für diese Heuristik in Pseudo-Code wie folgt definiert:

\begin{lstlisting}[style = dsl]
function applyHeuristic(proxies){
	return sort(proxies, qualRating)
}
\end{lstlisting}

\subsubsection{Quantitatives Rating}

\subsection{Testergebnisbasierte Heuristiken}
Die folgenden Heuristiken haben zum Ziel, basierend auf den fehlgeschlagenen Evaluationen von Proxies, darauf schließen, dass auch die Evaluation anderer Proxies fehlschlägt. Dadurch werden diese Proxies bei der weiteren Evaluation herausgefiltert.


\end{document}